{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DBLRE-fqlO5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AQvt6MHuS-b"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15.0\n",
        "!pip install tensorflow-addons --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xc-oRRVFMU0",
        "outputId": "4d60c3ef-1e72-457b-e12f-3a57d7b9bf51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c74UL9oI0VKU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import gesture_recognizer\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_save_dataset(input_dir, output_dir, train_ratio=0.7, val_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Membagi dataset menjadi training, validation, dan testing.\n",
        "    - input_dir: Folder asal dataset.\n",
        "    - output_dir: Folder tempat dataset hasil split akan disimpan.\n",
        "    - train_ratio: Rasio data untuk training.\n",
        "    - val_ratio: Rasio data untuk validation (sisanya untuk testing).\n",
        "    \"\"\"\n",
        "    # Hitung rasio untuk split\n",
        "    test_ratio = 1 - train_ratio - val_ratio\n",
        "\n",
        "    # Buat struktur folder output\n",
        "    for split in ['training', 'validation', 'testing']:\n",
        "        split_path = os.path.join(output_dir, split)\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    # Iterasi setiap kelas di folder input\n",
        "    for class_name in os.listdir(input_dir):\n",
        "        class_path = os.path.join(input_dir, class_name)\n",
        "\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        # Dapatkan semua file dalam folder kelas\n",
        "        files = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "        # Split dataset\n",
        "        train_files, temp_files = train_test_split(files, train_size=train_ratio, random_state=42)\n",
        "        val_files, test_files = train_test_split(temp_files, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)\n",
        "\n",
        "        # Fungsi untuk memindahkan file ke folder\n",
        "        def move_files(file_list, split):\n",
        "            split_class_path = os.path.join(output_dir, split, class_name)\n",
        "            os.makedirs(split_class_path, exist_ok=True)\n",
        "            for file in file_list:\n",
        "                shutil.copy(file, os.path.join(split_class_path, os.path.basename(file)))\n",
        "\n",
        "        # Pindahkan file ke folder masing-masing\n",
        "        move_files(train_files, 'training')\n",
        "        move_files(val_files, 'validation')\n",
        "        move_files(test_files, 'testing')\n",
        "\n",
        "# Path ke dataset awal dan folder hasil split\n",
        "input_dir = '/content/drive/MyDrive/asl_dataset'  # Folder dataset awal\n",
        "output_dir = '/content/splitt_asl_dataset'     # Folder hasil split\n",
        "\n",
        "split_and_save_dataset(input_dir, output_dir)"
      ],
      "metadata": {
        "id": "uw2VKhAY0sic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validasi hasil setelah splitting\n",
        "def count_files_in_split(output_dir):\n",
        "    for split in ['training', 'validation', 'testing']:\n",
        "        split_path = os.path.join(output_dir, split)\n",
        "        total_files = sum([len(files) for _, _, files in os.walk(split_path)])\n",
        "        print(f\"{split.capitalize()} files: {total_files}\")\n",
        "\n",
        "count_files_in_split('/content/splitt_asl_dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rArOX-cX1CYr",
        "outputId": "1efef177-0d57-4a2b-cfc9-e3117d3fbe6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: 1760\n",
            "Validation files: 359\n",
            "Testing files: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QgadM4VDj3Y2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3771ac61-4a01-4e01-efeb-1c9f5b954869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/splitt_asl_dataset/training\n",
            "['0', '6', 'f', 'b', 'v', '4', 'c', 'none', '7', '1', 'd', 'm', 'y', '2', '9', 'u', '3', '8', '5', 'x', 'l', 'n', 'a', 'o', 'h', 'k', 'q', 'g', 'p', 'e', 'j', 'r', 't', 'w', 's', 'z', 'i']\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/splitt_asl_dataset/training\"\n",
        "print(dataset_path)\n",
        "labels = []\n",
        "for i in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, i)\n",
        "    if os.path.isdir(folder_path):  # Pastikan hanya folder yang ditambahkan\n",
        "        labels.append(i)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cek apakah folder \"None\" ada dan hapus\n",
        "none_folder_path = os.path.join(dataset_path, \"none\")\n",
        "if os.path.exists(none_folder_path) and os.path.isdir(none_folder_path):\n",
        "    shutil.rmtree(none_folder_path)\n",
        "    print(f\"Folder 'none' berhasil dihapus.\")\n",
        "else:\n",
        "    print(\"Folder 'none' tidak ditemukan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of3Hvn4r52Gd",
        "outputId": "04ec81f3-de34-4970-d21a-a17426107f11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'none' berhasil dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan path ke folder dataset, misalnya ke folder \"training\"\n",
        "dataset_path = \"/content/splitt_asl_dataset/training\"\n",
        "\n",
        "# Buat folder 'None' jika belum ada\n",
        "none_folder_path = os.path.join(dataset_path, \"None\")\n",
        "if not os.path.exists(none_folder_path):\n",
        "    os.makedirs(none_folder_path)\n",
        "    print(f\"Folder 'None' berhasil dibuat di {none_folder_path}\")\n",
        "\n",
        "# Memuat dataset dengan preprocessing yang sesuai\n",
        "dataset = gesture_recognizer.Dataset.from_folder(\n",
        "    dirname=dataset_path,  # Pastikan path ini sesuai dengan folder 'training', 'validation', atau 'testing'\n",
        "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI11nQjC6_Oi",
        "outputId": "b3bdddbc-2a6c-4cf5-b069-f8974e3546bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aTTNZsolKXiT"
      },
      "outputs": [],
      "source": [
        "# data = gesture_recognizer.Dataset.from_folder(\n",
        "#     dirname=dataset_path,\n",
        "#     hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset path 2\n",
        "dataset_path_2 = \"/content/splitt_asl_dataset/validation\"\n",
        "\n",
        "# Buat folder 'None' jika belum ada\n",
        "none_folder_path = os.path.join(dataset_path_2, \"None\")\n",
        "if not os.path.exists(none_folder_path):\n",
        "    os.makedirs(none_folder_path)\n",
        "    print(f\"Folder 'None' berhasil dibuat di {none_folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBkgeSoP8fHa",
        "outputId": "76c36255-2f6f-419c-de0b-a1d759437891"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'None' berhasil dibuat di /content/splitt_asl_dataset/validation/None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATzNO-Tsa7kp",
        "outputId": "8f1ff5aa-9cca-4a50-eb10-838351771db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer  [(None, 128)]             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_  (None, 37)                4773      \n",
            " out (Dense)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5285 (20.64 KB)\n",
            "Trainable params: 5029 (19.64 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "492/492 [==============================] - 4s 6ms/step - loss: 2.6732 - categorical_accuracy: 0.2083 - val_loss: 1.0791 - val_categorical_accuracy: 0.6373 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 1.7172 - categorical_accuracy: 0.3872 - val_loss: 0.5768 - val_categorical_accuracy: 0.7549 - lr: 9.9000e-04\n",
            "Epoch 3/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 1.3181 - categorical_accuracy: 0.5122 - val_loss: 0.3936 - val_categorical_accuracy: 0.8088 - lr: 9.8010e-04\n",
            "Epoch 4/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 1.1073 - categorical_accuracy: 0.5589 - val_loss: 0.3198 - val_categorical_accuracy: 0.8284 - lr: 9.7030e-04\n",
            "Epoch 5/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 0.9307 - categorical_accuracy: 0.6250 - val_loss: 0.3097 - val_categorical_accuracy: 0.7941 - lr: 9.6060e-04\n",
            "Epoch 6/100\n",
            "492/492 [==============================] - 4s 7ms/step - loss: 0.8758 - categorical_accuracy: 0.6280 - val_loss: 0.3169 - val_categorical_accuracy: 0.8039 - lr: 9.5099e-04\n",
            "Epoch 7/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 0.8286 - categorical_accuracy: 0.6301 - val_loss: 0.3314 - val_categorical_accuracy: 0.8039 - lr: 9.4148e-04\n",
            "Epoch 8/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.7646 - categorical_accuracy: 0.6738 - val_loss: 0.3294 - val_categorical_accuracy: 0.7990 - lr: 9.3207e-04\n",
            "Epoch 9/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.7257 - categorical_accuracy: 0.6860 - val_loss: 0.3309 - val_categorical_accuracy: 0.7843 - lr: 9.2274e-04\n",
            "Epoch 10/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.7091 - categorical_accuracy: 0.6839 - val_loss: 0.3312 - val_categorical_accuracy: 0.7941 - lr: 9.1352e-04\n",
            "Epoch 11/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.6690 - categorical_accuracy: 0.7093 - val_loss: 0.3297 - val_categorical_accuracy: 0.8088 - lr: 9.0438e-04\n",
            "Epoch 12/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 0.6740 - categorical_accuracy: 0.7002 - val_loss: 0.3357 - val_categorical_accuracy: 0.7990 - lr: 8.9534e-04\n",
            "Epoch 13/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 0.6043 - categorical_accuracy: 0.7205 - val_loss: 0.3350 - val_categorical_accuracy: 0.8039 - lr: 8.8638e-04\n",
            "Epoch 14/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.6296 - categorical_accuracy: 0.7144 - val_loss: 0.3437 - val_categorical_accuracy: 0.7794 - lr: 8.7752e-04\n",
            "Epoch 15/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.6170 - categorical_accuracy: 0.7154 - val_loss: 0.3414 - val_categorical_accuracy: 0.8088 - lr: 8.6875e-04\n",
            "Epoch 16/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5704 - categorical_accuracy: 0.7520 - val_loss: 0.3517 - val_categorical_accuracy: 0.8039 - lr: 8.6006e-04\n",
            "Epoch 17/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5936 - categorical_accuracy: 0.7266 - val_loss: 0.3412 - val_categorical_accuracy: 0.7892 - lr: 8.5146e-04\n",
            "Epoch 18/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5730 - categorical_accuracy: 0.7439 - val_loss: 0.3417 - val_categorical_accuracy: 0.8137 - lr: 8.4294e-04\n",
            "Epoch 19/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.5803 - categorical_accuracy: 0.7470 - val_loss: 0.3839 - val_categorical_accuracy: 0.7990 - lr: 8.3451e-04\n",
            "Epoch 20/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5440 - categorical_accuracy: 0.7683 - val_loss: 0.3456 - val_categorical_accuracy: 0.8137 - lr: 8.2617e-04\n",
            "Epoch 21/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5273 - categorical_accuracy: 0.7459 - val_loss: 0.3653 - val_categorical_accuracy: 0.8039 - lr: 8.1791e-04\n",
            "Epoch 22/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5467 - categorical_accuracy: 0.7541 - val_loss: 0.3628 - val_categorical_accuracy: 0.8039 - lr: 8.0973e-04\n",
            "Epoch 23/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.5209 - categorical_accuracy: 0.7591 - val_loss: 0.3654 - val_categorical_accuracy: 0.7941 - lr: 8.0163e-04\n",
            "Epoch 24/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.5518 - categorical_accuracy: 0.7439 - val_loss: 0.3843 - val_categorical_accuracy: 0.7843 - lr: 7.9361e-04\n",
            "Epoch 25/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5431 - categorical_accuracy: 0.7612 - val_loss: 0.3632 - val_categorical_accuracy: 0.7990 - lr: 7.8568e-04\n",
            "Epoch 26/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5232 - categorical_accuracy: 0.7480 - val_loss: 0.3722 - val_categorical_accuracy: 0.7941 - lr: 7.7782e-04\n",
            "Epoch 27/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.5214 - categorical_accuracy: 0.7652 - val_loss: 0.3782 - val_categorical_accuracy: 0.7990 - lr: 7.7004e-04\n",
            "Epoch 28/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.5105 - categorical_accuracy: 0.7602 - val_loss: 0.3725 - val_categorical_accuracy: 0.8088 - lr: 7.6234e-04\n",
            "Epoch 29/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4819 - categorical_accuracy: 0.7774 - val_loss: 0.3925 - val_categorical_accuracy: 0.7990 - lr: 7.5472e-04\n",
            "Epoch 30/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4921 - categorical_accuracy: 0.7622 - val_loss: 0.3850 - val_categorical_accuracy: 0.8039 - lr: 7.4717e-04\n",
            "Epoch 31/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4905 - categorical_accuracy: 0.7825 - val_loss: 0.3769 - val_categorical_accuracy: 0.7990 - lr: 7.3970e-04\n",
            "Epoch 32/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4954 - categorical_accuracy: 0.7652 - val_loss: 0.3788 - val_categorical_accuracy: 0.8088 - lr: 7.3230e-04\n",
            "Epoch 33/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.5004 - categorical_accuracy: 0.7703 - val_loss: 0.3959 - val_categorical_accuracy: 0.8039 - lr: 7.2498e-04\n",
            "Epoch 34/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4853 - categorical_accuracy: 0.7795 - val_loss: 0.3860 - val_categorical_accuracy: 0.7990 - lr: 7.1773e-04\n",
            "Epoch 35/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4866 - categorical_accuracy: 0.7703 - val_loss: 0.3947 - val_categorical_accuracy: 0.8039 - lr: 7.1055e-04\n",
            "Epoch 36/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4995 - categorical_accuracy: 0.7764 - val_loss: 0.4142 - val_categorical_accuracy: 0.7990 - lr: 7.0345e-04\n",
            "Epoch 37/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4879 - categorical_accuracy: 0.7530 - val_loss: 0.3802 - val_categorical_accuracy: 0.8088 - lr: 6.9641e-04\n",
            "Epoch 38/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4786 - categorical_accuracy: 0.7846 - val_loss: 0.4151 - val_categorical_accuracy: 0.7941 - lr: 6.8945e-04\n",
            "Epoch 39/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4952 - categorical_accuracy: 0.7693 - val_loss: 0.4352 - val_categorical_accuracy: 0.7843 - lr: 6.8255e-04\n",
            "Epoch 40/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4831 - categorical_accuracy: 0.7744 - val_loss: 0.4065 - val_categorical_accuracy: 0.8039 - lr: 6.7573e-04\n",
            "Epoch 41/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4944 - categorical_accuracy: 0.7825 - val_loss: 0.4093 - val_categorical_accuracy: 0.7990 - lr: 6.6897e-04\n",
            "Epoch 42/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.5006 - categorical_accuracy: 0.7754 - val_loss: 0.4116 - val_categorical_accuracy: 0.7941 - lr: 6.6228e-04\n",
            "Epoch 43/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4520 - categorical_accuracy: 0.7805 - val_loss: 0.3924 - val_categorical_accuracy: 0.8235 - lr: 6.5566e-04\n",
            "Epoch 44/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4281 - categorical_accuracy: 0.8018 - val_loss: 0.4302 - val_categorical_accuracy: 0.8039 - lr: 6.4910e-04\n",
            "Epoch 45/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4329 - categorical_accuracy: 0.7957 - val_loss: 0.4140 - val_categorical_accuracy: 0.7990 - lr: 6.4261e-04\n",
            "Epoch 46/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4688 - categorical_accuracy: 0.7744 - val_loss: 0.3886 - val_categorical_accuracy: 0.8039 - lr: 6.3619e-04\n",
            "Epoch 47/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.4946 - categorical_accuracy: 0.7693 - val_loss: 0.3859 - val_categorical_accuracy: 0.8088 - lr: 6.2982e-04\n",
            "Epoch 48/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4589 - categorical_accuracy: 0.7978 - val_loss: 0.4067 - val_categorical_accuracy: 0.7892 - lr: 6.2353e-04\n",
            "Epoch 49/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4492 - categorical_accuracy: 0.7876 - val_loss: 0.3956 - val_categorical_accuracy: 0.8137 - lr: 6.1729e-04\n",
            "Epoch 50/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4697 - categorical_accuracy: 0.7774 - val_loss: 0.4345 - val_categorical_accuracy: 0.7990 - lr: 6.1112e-04\n",
            "Epoch 51/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4774 - categorical_accuracy: 0.7713 - val_loss: 0.4180 - val_categorical_accuracy: 0.8186 - lr: 6.0501e-04\n",
            "Epoch 52/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4214 - categorical_accuracy: 0.7957 - val_loss: 0.3832 - val_categorical_accuracy: 0.8088 - lr: 5.9896e-04\n",
            "Epoch 53/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4113 - categorical_accuracy: 0.7896 - val_loss: 0.4038 - val_categorical_accuracy: 0.7941 - lr: 5.9297e-04\n",
            "Epoch 54/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4775 - categorical_accuracy: 0.7846 - val_loss: 0.4192 - val_categorical_accuracy: 0.8039 - lr: 5.8704e-04\n",
            "Epoch 55/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4743 - categorical_accuracy: 0.7846 - val_loss: 0.3964 - val_categorical_accuracy: 0.8284 - lr: 5.8117e-04\n",
            "Epoch 56/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.4415 - categorical_accuracy: 0.7846 - val_loss: 0.3997 - val_categorical_accuracy: 0.8137 - lr: 5.7535e-04\n",
            "Epoch 57/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4148 - categorical_accuracy: 0.7866 - val_loss: 0.4007 - val_categorical_accuracy: 0.8088 - lr: 5.6960e-04\n",
            "Epoch 58/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4184 - categorical_accuracy: 0.7896 - val_loss: 0.4186 - val_categorical_accuracy: 0.8039 - lr: 5.6391e-04\n",
            "Epoch 59/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4334 - categorical_accuracy: 0.7866 - val_loss: 0.4258 - val_categorical_accuracy: 0.8039 - lr: 5.5827e-04\n",
            "Epoch 60/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4328 - categorical_accuracy: 0.7886 - val_loss: 0.3918 - val_categorical_accuracy: 0.8088 - lr: 5.5268e-04\n",
            "Epoch 61/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4315 - categorical_accuracy: 0.7856 - val_loss: 0.3933 - val_categorical_accuracy: 0.8137 - lr: 5.4716e-04\n",
            "Epoch 62/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4391 - categorical_accuracy: 0.7835 - val_loss: 0.4061 - val_categorical_accuracy: 0.7892 - lr: 5.4169e-04\n",
            "Epoch 63/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4447 - categorical_accuracy: 0.7724 - val_loss: 0.4235 - val_categorical_accuracy: 0.7990 - lr: 5.3627e-04\n",
            "Epoch 64/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4471 - categorical_accuracy: 0.7774 - val_loss: 0.3932 - val_categorical_accuracy: 0.8137 - lr: 5.3091e-04\n",
            "Epoch 65/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.4035 - categorical_accuracy: 0.8008 - val_loss: 0.3936 - val_categorical_accuracy: 0.8088 - lr: 5.2560e-04\n",
            "Epoch 66/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4391 - categorical_accuracy: 0.7896 - val_loss: 0.3759 - val_categorical_accuracy: 0.8186 - lr: 5.2034e-04\n",
            "Epoch 67/100\n",
            "492/492 [==============================] - 2s 4ms/step - loss: 0.4325 - categorical_accuracy: 0.7947 - val_loss: 0.3914 - val_categorical_accuracy: 0.7794 - lr: 5.1514e-04\n",
            "Epoch 68/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4435 - categorical_accuracy: 0.7907 - val_loss: 0.3813 - val_categorical_accuracy: 0.8088 - lr: 5.0999e-04\n",
            "Epoch 69/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4335 - categorical_accuracy: 0.7805 - val_loss: 0.4099 - val_categorical_accuracy: 0.7990 - lr: 5.0489e-04\n",
            "Epoch 70/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.4415 - categorical_accuracy: 0.7927 - val_loss: 0.3898 - val_categorical_accuracy: 0.8088 - lr: 4.9984e-04\n",
            "Epoch 71/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4105 - categorical_accuracy: 0.7724 - val_loss: 0.3847 - val_categorical_accuracy: 0.8235 - lr: 4.9484e-04\n",
            "Epoch 72/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.3980 - categorical_accuracy: 0.7957 - val_loss: 0.3775 - val_categorical_accuracy: 0.8039 - lr: 4.8989e-04\n",
            "Epoch 73/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4159 - categorical_accuracy: 0.8150 - val_loss: 0.3937 - val_categorical_accuracy: 0.8235 - lr: 4.8499e-04\n",
            "Epoch 74/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4516 - categorical_accuracy: 0.7815 - val_loss: 0.3896 - val_categorical_accuracy: 0.7892 - lr: 4.8014e-04\n",
            "Epoch 75/100\n",
            "492/492 [==============================] - 4s 9ms/step - loss: 0.4210 - categorical_accuracy: 0.8008 - val_loss: 0.4083 - val_categorical_accuracy: 0.7892 - lr: 4.7534e-04\n",
            "Epoch 76/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4362 - categorical_accuracy: 0.7805 - val_loss: 0.4117 - val_categorical_accuracy: 0.8088 - lr: 4.7059e-04\n",
            "Epoch 77/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4264 - categorical_accuracy: 0.7978 - val_loss: 0.3914 - val_categorical_accuracy: 0.8088 - lr: 4.6588e-04\n",
            "Epoch 78/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4389 - categorical_accuracy: 0.7866 - val_loss: 0.3985 - val_categorical_accuracy: 0.8186 - lr: 4.6122e-04\n",
            "Epoch 79/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4073 - categorical_accuracy: 0.7957 - val_loss: 0.3779 - val_categorical_accuracy: 0.8088 - lr: 4.5661e-04\n",
            "Epoch 80/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4391 - categorical_accuracy: 0.7917 - val_loss: 0.4066 - val_categorical_accuracy: 0.7990 - lr: 4.5204e-04\n",
            "Epoch 81/100\n",
            "492/492 [==============================] - 3s 7ms/step - loss: 0.4312 - categorical_accuracy: 0.7988 - val_loss: 0.3898 - val_categorical_accuracy: 0.8039 - lr: 4.4752e-04\n",
            "Epoch 82/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4327 - categorical_accuracy: 0.7866 - val_loss: 0.3967 - val_categorical_accuracy: 0.7843 - lr: 4.4305e-04\n",
            "Epoch 83/100\n",
            "492/492 [==============================] - 5s 10ms/step - loss: 0.4198 - categorical_accuracy: 0.8059 - val_loss: 0.3988 - val_categorical_accuracy: 0.7745 - lr: 4.3862e-04\n",
            "Epoch 84/100\n",
            "492/492 [==============================] - 4s 7ms/step - loss: 0.4222 - categorical_accuracy: 0.7937 - val_loss: 0.3746 - val_categorical_accuracy: 0.8137 - lr: 4.3423e-04\n",
            "Epoch 85/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4325 - categorical_accuracy: 0.7917 - val_loss: 0.4018 - val_categorical_accuracy: 0.8088 - lr: 4.2989e-04\n",
            "Epoch 86/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4235 - categorical_accuracy: 0.7825 - val_loss: 0.3974 - val_categorical_accuracy: 0.7941 - lr: 4.2559e-04\n",
            "Epoch 87/100\n",
            "492/492 [==============================] - 3s 7ms/step - loss: 0.4617 - categorical_accuracy: 0.7957 - val_loss: 0.3968 - val_categorical_accuracy: 0.7794 - lr: 4.2133e-04\n",
            "Epoch 88/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4262 - categorical_accuracy: 0.7907 - val_loss: 0.3888 - val_categorical_accuracy: 0.8039 - lr: 4.1712e-04\n",
            "Epoch 89/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4213 - categorical_accuracy: 0.7998 - val_loss: 0.3835 - val_categorical_accuracy: 0.8088 - lr: 4.1295e-04\n",
            "Epoch 90/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4499 - categorical_accuracy: 0.7856 - val_loss: 0.3854 - val_categorical_accuracy: 0.7794 - lr: 4.0882e-04\n",
            "Epoch 91/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4130 - categorical_accuracy: 0.7978 - val_loss: 0.3894 - val_categorical_accuracy: 0.7892 - lr: 4.0473e-04\n",
            "Epoch 92/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4414 - categorical_accuracy: 0.7795 - val_loss: 0.3786 - val_categorical_accuracy: 0.7892 - lr: 4.0068e-04\n",
            "Epoch 93/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4329 - categorical_accuracy: 0.7927 - val_loss: 0.4068 - val_categorical_accuracy: 0.7990 - lr: 3.9668e-04\n",
            "Epoch 94/100\n",
            "492/492 [==============================] - 2s 5ms/step - loss: 0.4098 - categorical_accuracy: 0.8171 - val_loss: 0.3963 - val_categorical_accuracy: 0.7892 - lr: 3.9271e-04\n",
            "Epoch 95/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4514 - categorical_accuracy: 0.7835 - val_loss: 0.3811 - val_categorical_accuracy: 0.8333 - lr: 3.8878e-04\n",
            "Epoch 96/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4307 - categorical_accuracy: 0.8059 - val_loss: 0.3910 - val_categorical_accuracy: 0.8088 - lr: 3.8490e-04\n",
            "Epoch 97/100\n",
            "492/492 [==============================] - 3s 5ms/step - loss: 0.4173 - categorical_accuracy: 0.7866 - val_loss: 0.3803 - val_categorical_accuracy: 0.8039 - lr: 3.8105e-04\n",
            "Epoch 98/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.4065 - categorical_accuracy: 0.8100 - val_loss: 0.4094 - val_categorical_accuracy: 0.8039 - lr: 3.7724e-04\n",
            "Epoch 99/100\n",
            "492/492 [==============================] - 3s 6ms/step - loss: 0.3974 - categorical_accuracy: 0.7876 - val_loss: 0.4075 - val_categorical_accuracy: 0.7696 - lr: 3.7346e-04\n",
            "Epoch 100/100\n",
            "492/492 [==============================] - 4s 8ms/step - loss: 0.4206 - categorical_accuracy: 0.7927 - val_loss: 0.3864 - val_categorical_accuracy: 0.8333 - lr: 3.6973e-04\n"
          ]
        }
      ],
      "source": [
        "hparams = gesture_recognizer.HParams(learning_rate=0.001, epochs=100, export_dir=\"exported_model_1\")\n",
        "model_options = gesture_recognizer.ModelOptions(dropout_rate=0.2)\n",
        "options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options, hparams=hparams)\n",
        "model_2 = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=gesture_recognizer.Dataset.from_folder(dirname=\"/content/splitt_asl_dataset/training\"),\n",
        "    validation_data=gesture_recognizer.Dataset.from_folder(dirname=\"/content/splitt_asl_dataset/validation\"),\n",
        "    options=options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0lpzdpyBN3K",
        "outputId": "cc0742cc-6e18-4269-ebf9-507910cfbe0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tflite to /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/canned_gesture_classifier.tflite to /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n",
            "best_model_weights.data-00000-of-00001\tcheckpoint    gesture_recognizer.task  metadata.json\n",
            "best_model_weights.index\t\tepoch_models  logs\n"
          ]
        }
      ],
      "source": [
        "model_2.export_model()\n",
        "!ls exported_model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1H3PDngpBXx-",
        "outputId": "0fd6b6ba-449a-4c13-bd5a-19f8bbd27b01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03b86d72-f1c2-4821-ac12-03eab6cd08b4\", \"gesture_recognizer.task\", 8477939)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "files.download('exported_model_1/gesture_recognizer.task')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}